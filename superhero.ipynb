{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21XXWP7Fpt2L"
      },
      "source": [
        "# Superhero (and Supervillain) Name Generator\n",
        "\n",
        "---\n",
        "\n",
        "[Superhero Names Dataset](https://github.com/am1tyadav/superhero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6P0NU5Cpt2R"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "1. Import the data\n",
        "2. Create a tokenizer\n",
        "3. Char to index and Index to char dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srULhalZpt2M",
        "outputId": "6eb66242-267f-4583-8508-50db3191157e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'superhero' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/am1tyadav/superhero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "uq4CLmsLpt2P",
        "outputId": "995179c0-aac0-440c-ce45-d1335db9489e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jumpa\\t\\ndoctor fate\\t\\nstarlight\\t\\nisildur\\t\\nlasher\\t\\nvarvara\\t\\nthe target\\t\\naxel\\t\\nbattra\\t\\nchangeling\\t\\npyrrh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "with open('superhero/superheroes.txt','r') as f:\n",
        "  data = f.read()\n",
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqhtLuAHpt2R",
        "outputId": "a279415d-cd48-4d10-a65c-4828227a7660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95Lo1Yqzpt2T"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~',\n",
        "    split='\\n',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYfC4sj2pt2V"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO4-dPM6pt2X",
        "outputId": "5cfb37f7-918e-4ee3-9475-7f1420391e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: '\\t', 2: 'a', 3: 'e', 4: 'r', 5: 'o', 6: 'n', 7: 'i', 8: ' ', 9: 't', 10: 's', 11: 'l', 12: 'm', 13: 'h', 14: 'd', 15: 'c', 16: 'u', 17: 'g', 18: 'k', 19: 'b', 20: 'p', 21: 'y', 22: 'w', 23: 'f', 24: 'v', 25: 'j', 26: 'z', 27: 'x', 28: 'q'}\n"
          ]
        }
      ],
      "source": [
        "char_to_index= tokenizer.word_index\n",
        "index_to_char = dict((v,k) for k,v in char_to_index.items())\n",
        "print(index_to_char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMwtIw_Bpt2Z"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "1. Converting between names and sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7iQLIXzpt2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b314e1d-f624-4605-a7c3-2a6dadfb350c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jumpa\\t',\n",
              " 'doctor fate\\t',\n",
              " 'starlight\\t',\n",
              " 'isildur\\t',\n",
              " 'lasher\\t',\n",
              " 'varvara\\t',\n",
              " 'the target\\t',\n",
              " 'axel\\t',\n",
              " 'battra\\t',\n",
              " 'changeling\\t']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "names = data.splitlines()\n",
        "names[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_-TTfqipt2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8904f8-3256-4c1e-b6f6-f637d6e34e6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25], [16], [12], [20], [2], [1]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(names[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6IsKH1Upt2e"
      },
      "outputs": [],
      "source": [
        "def name_to_seq(name):\n",
        "  return [tokenizer.texts_to_sequences(c)[0][0] for c in name ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuLUiMP3pt2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9813ca-5f9f-4524-901a-98bad26288b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 16, 12, 20, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "name_to_seq(names[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFUYhimKpt2h"
      },
      "outputs": [],
      "source": [
        "def seq_to_name(seq):\n",
        "  return ''.join([index_to_char[i] for i in seq if i != 0 ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROhCqmhLpt2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74db7d84-89a1-4371-a98d-576346de9456"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jumpa\\t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "seq_to_name(name_to_seq(names[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCbAzsNjpt2m"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "1. Creating sequences\n",
        "2. Padding all sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zstNn-0dpt2m"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "\n",
        "for name in names:\n",
        "  seq = name_to_seq(name)\n",
        "  if len(seq) >= 2:\n",
        "    sequences += [seq[:i] for i in range(2,len(seq)+1 )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjRTMysvpt2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0187a0-200a-447e-8d03-b5ea882a312f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25, 16],\n",
              " [25, 16, 12],\n",
              " [25, 16, 12, 20],\n",
              " [25, 16, 12, 20, 2],\n",
              " [25, 16, 12, 20, 2, 1],\n",
              " [14, 5],\n",
              " [14, 5, 15],\n",
              " [14, 5, 15, 9],\n",
              " [14, 5, 15, 9, 5],\n",
              " [14, 5, 15, 9, 5, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR68pu2tpt2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f71ded-1242-4379-a523-9889e0174bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ],
      "source": [
        "max_len = max(len(x) for x in sequences)\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_1BtWO7pt2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10cb84b-4b61-44ce-864c-2127fb74d9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0 25 16]\n"
          ]
        }
      ],
      "source": [
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences, padding='pre',\n",
        "    maxlen = max_len\n",
        ")\n",
        "print(padded_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPlrLRpSpt2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a154bc11-a188-4272-9eb7-e1273b1a3f52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88279, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "padded_sequences.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJOEH_6ir4HZ"
      },
      "source": [
        "## Task 5: Creating Training and Validation Sets\n",
        "\n",
        "1. Creating training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE4BIeSnpt2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38dcb7bd-6c26-439b-b7e7-524d27f3db3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(88279, 32) (88279,)\n"
          ]
        }
      ],
      "source": [
        "x ,y = padded_sequences[:,:-1], padded_sequences[:,-1]\n",
        "print(x.shape,y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeofXj1qr4Ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a213e0-f5b9-41de-a9a7-7737b53258e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66209, 32) (66209,)\n",
            "(22070, 32) (22070,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train,y_test = train_test_split(x,y)\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgqRZtqnpt2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca066a1-5ca3-4521-f5d5-4470e87b4ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n"
          ]
        }
      ],
      "source": [
        "num_chars = len(char_to_index.keys())+1\n",
        "print(num_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TUv6m9hr4Ha"
      },
      "source": [
        "## Task 6: Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUO2jBn7r4Ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3fc9d7-0078-4217-c632-bb57819ea8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 32, 8)             232       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 32, 64)            2624      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 16, 64)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 29)                957       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,229\n",
            "Trainable params: 16,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,Conv1D, MaxPool1D,LSTM\n",
        "from tensorflow.keras.layers import Bidirectional, Dense\n",
        "\n",
        "model = Sequential([\n",
        "                   Embedding(num_chars,8,input_length = max_len-1),\n",
        "                   Conv1D(64,5,strides=1,activation='tanh',padding='causal'),\n",
        "                    MaxPool1D(2),\n",
        "                    LSTM(32),\n",
        "                    Dense(num_chars,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHdVj96mr4Ha"
      },
      "source": [
        "## Task 7: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0Ssl4qupt22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d3376d-7a32-4d7c-a498-88acbe67e6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2070/2070 - 20s - loss: 2.7390 - accuracy: 0.1888 - val_loss: 2.5741 - val_accuracy: 0.2224 - 20s/epoch - 10ms/step\n",
            "Epoch 2/50\n",
            "2070/2070 - 17s - loss: 2.5409 - accuracy: 0.2357 - val_loss: 2.4926 - val_accuracy: 0.2510 - 17s/epoch - 8ms/step\n",
            "Epoch 3/50\n",
            "2070/2070 - 17s - loss: 2.4718 - accuracy: 0.2538 - val_loss: 2.4365 - val_accuracy: 0.2629 - 17s/epoch - 8ms/step\n",
            "Epoch 4/50\n",
            "2070/2070 - 17s - loss: 2.4209 - accuracy: 0.2662 - val_loss: 2.3986 - val_accuracy: 0.2692 - 17s/epoch - 8ms/step\n",
            "Epoch 5/50\n",
            "2070/2070 - 17s - loss: 2.3833 - accuracy: 0.2752 - val_loss: 2.3768 - val_accuracy: 0.2820 - 17s/epoch - 8ms/step\n",
            "Epoch 6/50\n",
            "2070/2070 - 17s - loss: 2.3512 - accuracy: 0.2849 - val_loss: 2.3560 - val_accuracy: 0.2864 - 17s/epoch - 8ms/step\n",
            "Epoch 7/50\n",
            "2070/2070 - 20s - loss: 2.3231 - accuracy: 0.2944 - val_loss: 2.3338 - val_accuracy: 0.2890 - 20s/epoch - 10ms/step\n",
            "Epoch 8/50\n",
            "2070/2070 - 18s - loss: 2.2988 - accuracy: 0.3014 - val_loss: 2.3166 - val_accuracy: 0.3019 - 18s/epoch - 8ms/step\n",
            "Epoch 9/50\n",
            "2070/2070 - 17s - loss: 2.2779 - accuracy: 0.3072 - val_loss: 2.3067 - val_accuracy: 0.3042 - 17s/epoch - 8ms/step\n",
            "Epoch 10/50\n",
            "2070/2070 - 17s - loss: 2.2580 - accuracy: 0.3141 - val_loss: 2.2951 - val_accuracy: 0.3108 - 17s/epoch - 8ms/step\n",
            "Epoch 11/50\n",
            "2070/2070 - 20s - loss: 2.2402 - accuracy: 0.3206 - val_loss: 2.2855 - val_accuracy: 0.3093 - 20s/epoch - 10ms/step\n",
            "Epoch 12/50\n",
            "2070/2070 - 17s - loss: 2.2236 - accuracy: 0.3272 - val_loss: 2.2735 - val_accuracy: 0.3163 - 17s/epoch - 8ms/step\n",
            "Epoch 13/50\n",
            "2070/2070 - 17s - loss: 2.2075 - accuracy: 0.3310 - val_loss: 2.2668 - val_accuracy: 0.3179 - 17s/epoch - 8ms/step\n",
            "Epoch 14/50\n",
            "2070/2070 - 17s - loss: 2.1930 - accuracy: 0.3366 - val_loss: 2.2559 - val_accuracy: 0.3218 - 17s/epoch - 8ms/step\n",
            "Epoch 15/50\n",
            "2070/2070 - 17s - loss: 2.1778 - accuracy: 0.3424 - val_loss: 2.2529 - val_accuracy: 0.3284 - 17s/epoch - 8ms/step\n",
            "Epoch 16/50\n",
            "2070/2070 - 17s - loss: 2.1647 - accuracy: 0.3475 - val_loss: 2.2413 - val_accuracy: 0.3333 - 17s/epoch - 8ms/step\n",
            "Epoch 17/50\n",
            "2070/2070 - 17s - loss: 2.1524 - accuracy: 0.3522 - val_loss: 2.2356 - val_accuracy: 0.3320 - 17s/epoch - 8ms/step\n",
            "Epoch 18/50\n",
            "2070/2070 - 17s - loss: 2.1402 - accuracy: 0.3559 - val_loss: 2.2336 - val_accuracy: 0.3372 - 17s/epoch - 8ms/step\n",
            "Epoch 19/50\n",
            "2070/2070 - 17s - loss: 2.1292 - accuracy: 0.3604 - val_loss: 2.2256 - val_accuracy: 0.3399 - 17s/epoch - 8ms/step\n",
            "Epoch 20/50\n",
            "2070/2070 - 17s - loss: 2.1186 - accuracy: 0.3622 - val_loss: 2.2215 - val_accuracy: 0.3407 - 17s/epoch - 8ms/step\n",
            "Epoch 21/50\n",
            "2070/2070 - 17s - loss: 2.1083 - accuracy: 0.3680 - val_loss: 2.2223 - val_accuracy: 0.3423 - 17s/epoch - 8ms/step\n",
            "Epoch 22/50\n",
            "2070/2070 - 17s - loss: 2.0984 - accuracy: 0.3686 - val_loss: 2.2121 - val_accuracy: 0.3437 - 17s/epoch - 8ms/step\n",
            "Epoch 23/50\n",
            "2070/2070 - 17s - loss: 2.0889 - accuracy: 0.3719 - val_loss: 2.2117 - val_accuracy: 0.3454 - 17s/epoch - 8ms/step\n",
            "Epoch 24/50\n",
            "2070/2070 - 17s - loss: 2.0792 - accuracy: 0.3763 - val_loss: 2.2093 - val_accuracy: 0.3411 - 17s/epoch - 8ms/step\n",
            "Epoch 25/50\n",
            "2070/2070 - 17s - loss: 2.0711 - accuracy: 0.3778 - val_loss: 2.2044 - val_accuracy: 0.3455 - 17s/epoch - 8ms/step\n",
            "Epoch 26/50\n",
            "2070/2070 - 17s - loss: 2.0624 - accuracy: 0.3799 - val_loss: 2.2119 - val_accuracy: 0.3465 - 17s/epoch - 8ms/step\n",
            "Epoch 27/50\n",
            "2070/2070 - 17s - loss: 2.0547 - accuracy: 0.3826 - val_loss: 2.2012 - val_accuracy: 0.3524 - 17s/epoch - 8ms/step\n",
            "Epoch 28/50\n",
            "2070/2070 - 17s - loss: 2.0469 - accuracy: 0.3861 - val_loss: 2.1999 - val_accuracy: 0.3508 - 17s/epoch - 8ms/step\n",
            "Epoch 29/50\n",
            "2070/2070 - 17s - loss: 2.0404 - accuracy: 0.3867 - val_loss: 2.1984 - val_accuracy: 0.3537 - 17s/epoch - 8ms/step\n",
            "Epoch 30/50\n",
            "2070/2070 - 17s - loss: 2.0344 - accuracy: 0.3894 - val_loss: 2.1986 - val_accuracy: 0.3523 - 17s/epoch - 8ms/step\n",
            "Epoch 31/50\n",
            "2070/2070 - 17s - loss: 2.0277 - accuracy: 0.3911 - val_loss: 2.1953 - val_accuracy: 0.3548 - 17s/epoch - 8ms/step\n",
            "Epoch 32/50\n",
            "2070/2070 - 17s - loss: 2.0213 - accuracy: 0.3919 - val_loss: 2.1957 - val_accuracy: 0.3522 - 17s/epoch - 8ms/step\n",
            "Epoch 33/50\n",
            "2070/2070 - 17s - loss: 2.0154 - accuracy: 0.3930 - val_loss: 2.1914 - val_accuracy: 0.3545 - 17s/epoch - 8ms/step\n",
            "Epoch 34/50\n",
            "2070/2070 - 18s - loss: 2.0094 - accuracy: 0.3963 - val_loss: 2.1916 - val_accuracy: 0.3504 - 18s/epoch - 9ms/step\n"
          ]
        }
      ],
      "source": [
        "h = model.fit(\n",
        "    x_train,y_train,\n",
        "    validation_data =(x_test,y_test),\n",
        "    epochs=50,verbose=2,\n",
        "    callbacks=  [\n",
        "                 tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3)\n",
        "    ]\n",
        "    \n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h.history['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSdKAdwqpEN4",
        "outputId": "6ab5e0bd-ee45-4f0e-b999-75f5588473a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-J742ONr4Hb"
      },
      "source": [
        "## Task 8: Generate Names!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f50aTRcpt24"
      },
      "outputs": [],
      "source": [
        "def generate_names(seed):\n",
        "  for i in range(0,40):\n",
        "    seq = name_to_seq(seed)\n",
        "    padded = tf.keras.preprocessing.sequence.pad_sequences([seq],padding='pre',\n",
        "                                                           maxlen= max_len-1,\n",
        "                                                           truncating='pre')\n",
        "    pred = model.predict(padded)[0]\n",
        "    pred_char = index_to_char[tf.argmax(pred).numpy()]\n",
        "    seed += pred_char\n",
        "\n",
        "    if pred_char == '\\t':\n",
        "      break\n",
        "    print(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faQ0FInlpt26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7fa9a4-7abe-49b1-c80d-5852e7fba1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fa\n",
            "far\n",
            "fark\n",
            "farke\n",
            "farkel\n",
            "farkell\n",
            "farkella\n",
            "farkellad\n"
          ]
        }
      ],
      "source": [
        "generate_names('f')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Superhero Name Generator - Learner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}